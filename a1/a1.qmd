---
title: "CSC 485 A1"
format:
  html:
    code-fold: true
jupyter: python3
---

## Question 1

### Part 1

We need to figure out the capacity of the cylinders. A cylinder is all the tracks that line up vertically. There are 10 surfaces, so each cylinder is composed of 10 tracks. The capacity of each track is 1000 sectors, so the capacity of each cylinder is 10,000 sectors. The capacity of an average sector is 512 bytes, so the capacity of each cylinder is $10 \times 1000 \times 512$ = 5,120,000 bytes.

### Part 2

If a block were 32 sectors, then two consecutive blocks would be 64 sectors. There's also a gap between each sector, and 20% of the track is used for gaps. If a track has 1000 sectors and 1000 gaps, and the gaps use 20% of the space, then the gaps are a quarter the size of the sectors. Since we're reading 64 sectors, we also need to pass over 63 gaps between sectors so 64\*sector_width + 63\*0.25*sector_width. One sector + one gap makes up $\frac{1}{1000}$ of a track, so one sector = $\frac{0.8}{1000}$ and one track = $\frac{0.2}{1000}$ of the track. So we have $\frac{64(0.8) + 63(0.2)}{1000} = \frac{63.8}{1000}$ of the track. And if we can rotate at 10000 rpm, then it takes us $\frac{63.8}{1000} \frac{1}{10000}$ minutes to cover this distance, or $63.8(10^{-7})(60)$ seconds assuming that we don't need to seek to the first sector.


### Part 3

We need to find the average time to update two blocks of data on the same track, assuming that the head is already on the track. We cannot assume that the two blocks are consecutive, so our time is


* half rotation (find start of block 1)
* full rotation (read block 1, wait for beginning of block 2, read block 2, get back to start of block 1)
* half rotation (write block 1, get back to start of block 2, write block 2)

Which is equal to two full rotations, so at 10000 rpm that's $2\frac{60}{10000}$ seconds, or 0.012 seconds.

### Part 4

Disk head starts on track 2500, so it's 25% of the way into the disk. It moves to some random track T, which is uniformly distributed between 1 and 10000. So 0.25 of the time the head has to move back out, and 75% of the time it has to move in. The expected amount for it to move out is 1250 tracks, and the expected amount for it to move in is 3750 tracks. So the expected amount of seeking is 0.25 * 1250 + 0.75 * 3750 = 3125 tracks, so our seek time is 1 + 3125 * 0.001 = 4.125 ms.

Now we're on the right track, but we have to spin an expected 180 degrees to get to the right block, so 0.5 * 1/10000 * 60 * 1000 = 3ms

Then we have to read the block. Assuming that the block is 32 sectors, we need to read them all, as well as the gaps in between. So we have $\frac{32 * 0.8 + 31 * 0.2}{1000} $ of a rotation, and one rotation takes 1/10000 * 60 * 1000 = 6ms, so our read time is $\frac{32 * 0.8 + 31 * 0.2}{1000} * 6$ = 0.19 ms.

Adding it all up we have 4.125 + 3 + 0.19 = 7.315 ms.


## Question 2

The relation $R$ grows to have as many tuples (160 bytes each) to the maximum size that can be sorted by PMM2S on the Megatron 747 described in the slides.


* Our block size is $B = 16384$ bytes
* Our main memory size is $M = 100$ MB
* Our record size is $R = 160$ bytes
* Our disk i/o time is 11 ms
* Our number of main memory buffers is $\frac{M}{B}$ blocks
* We need an output buffer, so our actual number of input buffers is $\frac{M}{B} -1$ blocks
* Each time we fill our memory with $\frac{M}{R}$ records
* Therefore we are able to sort $\frac{M}{R} (\frac{M}{B} -1) \approx \frac{M^2}{RB}$ records
* So we can sort $\lfloor \frac{100000000^{2}}{(16384)(160)} \rfloor = 3814697265$ records
* Each block can hold $\frac{16384}{160} = 102$ records
* So the relation is $\lceil \frac{3814697265}{102} \rceil = 37398993$ blocks
* Thus we need $37398993 * 4$ disk i/o operations to sort the relation
* Which is a total time of $37398993 * 4 * 11$ ms = 1645555692 ms $\approx$ 457 hours $\approx$ 19 days


## Question 3

We need one pass algorithms for 

* R Left Join S (R in memory)
* R Left Join S (S in memory)
* R Full Join S (R in memory)

### R Left Join S (R in memory)

* First, read $R$ into memory, taking up $M-1$ buffers. Then read sections of $S$ into the last buffer, one at a time. 

* Build a search structure where the search key is the shared attributes of R and S

* For each tuple $t$ in $S$, we check if it joins any tuple $u$ in $R$. If it does, we output the join of $t$ with $u$.

* We also output any tuple $u$ in $R$ that does not join with any tuple in $S$, we output $u$ with null values for the attributes in $S$ since it is a left join.

### R Left Join S (S in memory)

* First, read $S$ into memory, taking up $M-1$ buffers. Then read sections of $R$ into the last buffer, one at a time.

* Build a search structure where the search key is the shared attributes of R and S

* For each tuple $t$ in $R$, we check if it joins any tuple $u$ in $S$. If it does, we output the join of $t$ with $u$, if not we just output $t$ with null values for the attributes of $S$.

### R Full Join S (R in memory)

* First, read $R$ into memory, taking up $M-1$ buffers. Then read sections of $S$ into the last buffer, one at a time.

* For each tuple $t$ in the block of $S$, we check if it joins with any tuple in $u$ $R$. If it does, we output the join of $t$ with $u$. If not, we output $t$ with a null value for the attributes in $R$.

* We also output any tuple $u$ in $R$ that does not join with any tuple in $S$, since it is a full join, again with null values for attributes in $S$.


## Question 4

In order to do a 2 pass sort-join of R,S we first need to sort them:

* First, sort $S$. Using the PMM2S algorithm, we can sort $S$ in $2 * 500$ disk i/o operations, which takes $2 * 500 * 11$ ms = 11000 ms
* Then we sort $R$, using the PMM2S algorithm, we can sort $R$ in $2* 1000$ disk i/o operations, which takes $2 * 1000 * 11$ ms = 22000 ms
* Then we do a 2 pass join, so since $S$ is smaller we'd read it into memory 100 blocks at a time in the outer loop.
* In the inner loop we'd read all of $R$ into memory 1 block at a time, and do a nested loop join.
* Since we stored the sorted $R$ in consecutive blocks, we only need to seek once per outer loop to get to the start of $R$, then we can read $R$ sequentially for the rest of the inner loop.
* So each iteration of the outer loop is time to seek to the segment of $S$ we need + read in 100 blocks of $S$ + seek to start of $R$ + read all of $R$ = 15ms + 100 * 0.4ms + 15 ms + 1000 * 0.4ms = 15ms + 40ms + 15ms + 400ms = 470ms
* We need to run the outer loop 5 times, so the total time is 5 * 470ms = 2350ms
* So the total cost is 11000ms + 22000ms + 2350ms = 35350ms



## Question 5

### Part 1

Disks 1 and 7 have failed, so we need to recover the data on them. We can do this by using the parity information on the other disks. 

Lets draw out the matrix for RAID 6

$$
\begin{pmatrix}
1,1,1,0,1,0,0\\
1,1,0,1,0,1,0\\
1,0,1,1,0,0,1\\
\end{pmatrix}
$$

We can see that disk 1 participates in RAID 4 in each of these rows, and disk 7 participates in RAID 4 in the last row. We need to find a row where the bits for disk 1 and 7 are different. This can be either row 1 or row 2. Lets say we choose row 1. Then we can recover the data on disk 1 by XORing the data on disk 2,3 and 5. Once we've recovered disk 1, we can recover disk 7 by XORing the data on disk 1, 3, and 4 since 7 has a 1 on the last row.

### Part 2
Disk 1 and 4 have failed. Using the matrix from part 1, we find a row where disk 1 and 4 have different bits. This is row 1. We can recover disk 1 by XORing the data on disk 2, 3, and 5. We can then find a row where disk 4s bit is 1, row 2 or 3. Lets say we choose row 2. We can recover disk 4 by XORing the data on disk 1, 2, and 6.

### Part 3

Disks 3 and 6 have failed. Using the matrix we can find a row where they have different bits. This is row 1. We can recover disk 3 by XORing the data on disk 1, 2, and 5. We can then find a row where disk 6s bit is 1, row 2. We can recover disk 6 by XORing the data on disk 1, 2, and 4.


## Question 6

<!-- The parity checks of disks 9 and 10 can be represented by the matrix

1    2    3    4    5    6    7    8    9    10   11
------------------------------------------------------
1    1    1    1    0    0    0    0    1    0    0
0    0    0    0    1    1    1    1    0    1    0
?    ?    ?    ?    ?    ?    ?    ?    0    0    1

Before we add a third row representing the parity check of disk 11, recall that we can recover from two disk failures if and only if the two disks have different columns. 
We want to maximize the number of pairs of disks that no longer have identical columns.  
As is now, 1,2,3,4 have identical columns, and also 5,6,7,8 have identical columns. Where to put 1 for “?” and where 0, so that we get the greatest number of non-identical columns? 

1    2    3    4    5    6    7    8    9    10   11
------------------------------------------------------
1    1    1    1    0    0    0    0    1    0    0
0    0    0    0    1    1    1    1    0    1    0
1    0    1    0    1    0    1    0    0    0    1

With this configuration we have 4 distinct columns, 1,3 + 2,4 + 5,7 + 6,8. This is the best we can do, since the way disks 9 and 10 are configured, there is no overlap between them, so we only have 2 distinct columns per group. So we can only double the amount of existing distinct columns, which is 2, to get 4. -->

::: layout="center" 
![](https://i.imgur.com/7JYXinJ.png)
:::